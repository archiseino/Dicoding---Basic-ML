{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection vs Feature Extraction\n",
    "Basically feature selection just pick thes best feature from many features available, contrast to the Feature Extraction, it creates a new features in a simplest way\n",
    "\n",
    "One example of Features Extraction is by PCA (Principle Component Analysis) that takes the features and combined them by it's weight of the component to summarize the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The codelab is focused on the Supervised Feature Selection, like huh?\n",
    "![image](https://dicoding-web-img.sgp1.cdn.digitaloceanspaces.com/original/academy/dos-da81bea4049e584eaefd7f6c92b1024d20241016171352.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "Tujuan utama dari unsupervised feature selection adalah mengurangi dimensionalitas data dengan mengidentifikasi fitur-fitur yang paling relevan atau signifikan untuk meningkatkan efisiensi algoritma machine learning dan mempermudah visualisasi data tanpa menghiraukan label target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Supervised feature selection adalah proses memilih fitur yang paling relevan dari dataset dengan memanfaatkan informasi dari label atau target variabel. Hal ini berarti pemilihan fitur dilakukan dengan memperhatikan hubungan antara setiap fitur dan variabel target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the dataset `load_wine` from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memuat dataset Wine Quality\n",
    "data = load_wine()\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  target  \n",
       "0                            3.92   1065.0       0  \n",
       "1                            3.40   1050.0       0  \n",
       "2                            3.17   1185.0       0  \n",
       "3                            3.45   1480.0       0  \n",
       "4                            2.93    735.0       0  \n",
       "..                            ...      ...     ...  \n",
       "173                          1.74    740.0       2  \n",
       "174                          1.56    750.0       2  \n",
       "175                          1.56    835.0       2  \n",
       "176                          1.62    840.0       2  \n",
       "177                          1.60    560.0       2  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mengubah menjadi DataFrame untuk analisis yang lebih mudah\n",
    "df = pd.DataFrame(X, columns=data.feature_names)\n",
    "df['target'] = y\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          alcohol  malic_acid         ash  alcalinity_of_ash   magnesium  \\\n",
      "count  178.000000  178.000000  178.000000         178.000000  178.000000   \n",
      "mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n",
      "std      0.811827    1.117146    0.274344           3.339564   14.282484   \n",
      "min     11.030000    0.740000    1.360000          10.600000   70.000000   \n",
      "25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n",
      "50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n",
      "75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n",
      "max     14.830000    5.800000    3.230000          30.000000  162.000000   \n",
      "\n",
      "       total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
      "count     178.000000  178.000000            178.000000       178.000000   \n",
      "mean        2.295112    2.029270              0.361854         1.590899   \n",
      "std         0.625851    0.998859              0.124453         0.572359   \n",
      "min         0.980000    0.340000              0.130000         0.410000   \n",
      "25%         1.742500    1.205000              0.270000         1.250000   \n",
      "50%         2.355000    2.135000              0.340000         1.555000   \n",
      "75%         2.800000    2.875000              0.437500         1.950000   \n",
      "max         3.880000    5.080000              0.660000         3.580000   \n",
      "\n",
      "       color_intensity         hue  od280/od315_of_diluted_wines      proline  \\\n",
      "count       178.000000  178.000000                    178.000000   178.000000   \n",
      "mean          5.058090    0.957449                      2.611685   746.893258   \n",
      "std           2.318286    0.228572                      0.709990   314.907474   \n",
      "min           1.280000    0.480000                      1.270000   278.000000   \n",
      "25%           3.220000    0.782500                      1.937500   500.500000   \n",
      "50%           4.690000    0.965000                      2.780000   673.500000   \n",
      "75%           6.200000    1.120000                      3.170000   985.000000   \n",
      "max          13.000000    1.710000                      4.000000  1680.000000   \n",
      "\n",
      "           target  \n",
      "count  178.000000  \n",
      "mean     0.938202  \n",
      "std      0.775035  \n",
      "min      0.000000  \n",
      "25%      0.000000  \n",
      "50%      1.000000  \n",
      "75%      2.000000  \n",
      "max      2.000000  \n"
     ]
    }
   ],
   "source": [
    "## Describe datset\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pembagian data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Method\n",
    "Technique to see how relevant the feature as independently in the model. This method doesn't use the non-sense ML procses so it much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitur yang dipilih dengan Filter Methods: [ 9 12]\n"
     ]
    }
   ],
   "source": [
    "# ------------------- Filter Methods -------------------\n",
    "# Menggunakan SelectKBest\n",
    "filter_selector = SelectKBest(score_func=chi2, k=2)  # Memilih 2 fitur terbaik\n",
    "X_train_filter = filter_selector.fit_transform(X_train, y_train)\n",
    "X_test_filter = filter_selector.transform(X_test)\n",
    " \n",
    "print(\"Fitur yang dipilih dengan Filter Methods:\", filter_selector.get_support(indices=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Wrapped Methods\n",
    "Metode ini secara iteratif akan menambah atau menghapus fitur dengan tujuan untuk menemukan kombinasi yang menghasilkan kinerja model terbaik. Dalam penggunaannya Anda dapat menggunakan beberapa teknik untuk memaksimalkan proses feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitur yang dipilih dengan Wrapper Methods: [0 6]\n"
     ]
    }
   ],
   "source": [
    "# Menggunakan RFE (Recursive Feature Elimination)\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=5000)\n",
    "rfe_selector = RFE(model, n_features_to_select=2)  # Memilih 2 fitur\n",
    "X_train_rfe = rfe_selector.fit_transform(X_train, y_train)\n",
    "X_test_rfe = rfe_selector.transform(X_test)\n",
    " \n",
    "print(\"Fitur yang dipilih dengan Wrapper Methods:\", rfe_selector.get_support(indices=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded Methods\n",
    "Let's do both, takes the feature and check on the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitur yang dipilih dengan Embedded Methods (di atas ambang batas):\n",
      "alcohol: 0.11239773542143086\n",
      "flavanoids: 0.20229341635663622\n",
      "color_intensity: 0.1712021830864957\n",
      "hue: 0.07089132259413944\n",
      "od280/od315_of_diluted_wines: 0.1115643167260497\n",
      "proline: 0.13904586955351153\n",
      "\n",
      "Dimensi data pelatihan dengan fitur penting: (142, 6)\n",
      "Dimensi data pengujian dengan fitur penting: (36, 6)\n"
     ]
    }
   ],
   "source": [
    "# ------------------- Embedded Methods -------------------\n",
    "# Menggunakan Random Forest untuk mendapatkan fitur penting\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    " \n",
    "# Mendapatkan fitur penting\n",
    "importances = rf_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    " \n",
    "# Menentukan ambang batas untuk fitur penting\n",
    "threshold = 0.05  # Misalnya, ambang batas 5%\n",
    "important_features_indices = [i for i in range(len(importances)) if importances[i] >= threshold]\n",
    " \n",
    "# Memindahkan fitur penting ke variabel baru\n",
    "X_important = X_train[:, important_features_indices]  # Hanya fitur penting dari data pelatihan\n",
    "X_test_important = X_test[:, important_features_indices]  # Hanya fitur penting dari data pengujian\n",
    " \n",
    "# Mencetak fitur yang dipilih\n",
    "print(\"Fitur yang dipilih dengan Embedded Methods (di atas ambang batas):\")\n",
    "for i in important_features_indices:\n",
    "    print(f\"{data.feature_names[i]}: {importances[i]}\")\n",
    " \n",
    "# X_important sekarang berisi hanya fitur penting\n",
    "print(\"\\nDimensi data pelatihan dengan fitur penting:\", X_important.shape)\n",
    "print(\"Dimensi data pengujian dengan fitur penting:\", X_test_important.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi dengan fitur terpilih dari masing-masing metode\n",
    "def evaluate_model(X_train, X_test, y_train, y_test, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.score(X_test, y_test)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Logistic Regression untuk Filter Methods\n",
    "logistic_model_filter = LogisticRegression(max_iter=200)\n",
    "accuracy_filter = evaluate_model(X_train_filter, X_test_filter, y_train, y_test, logistic_model_filter)\n",
    " \n",
    "# Model Logistic Regression untuk Wrapper Methods\n",
    "logistic_model_rfe = LogisticRegression(max_iter=200)\n",
    "accuracy_rfe = evaluate_model(X_train_rfe, X_test_rfe, y_train, y_test, logistic_model_rfe)\n",
    " \n",
    "# Model Random Forest untuk Embedded Methods\n",
    "accuracy_rf = evaluate_model(X_important, X_test_important, y_train, y_test, rf_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Akurasi Model dengan Filter Methods: 0.89\n",
      "Akurasi Model dengan Wrapper Methods: 0.94\n",
      "Akurasi Model dengan Embedded Methods: 1.00\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nAkurasi Model dengan Filter Methods: {accuracy_filter:.2f}\")\n",
    "print(f\"Akurasi Model dengan Wrapper Methods: {accuracy_rfe:.2f}\")\n",
    "print(f\"Akurasi Model dengan Embedded Methods: {accuracy_rf:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codex_astartes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
